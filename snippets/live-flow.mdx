import Samples from '/snippets/samples.mdx';

## Initiate your real-time session

First, call the [`POST /v2/live` endpoint](/api-reference/v2/live/init) and pass your configuration.
It's important to correctly define the properties `encoding`, `sample_rate`, `bit_depth` and `channels` as we need them to parse your audio chunks.

<CodeGroup>
  ```javascript JavaScript
    const response = await fetch('https://api.gladia.io/v2/live', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-Gladia-Key': '<YOUR_GLADIA_API_KEY>',
      },
      body: JSON.stringify({
        encoding: 'wav/pcm',
        sample_rate: 16000,
        bit_depth: 16,
        channels: 1,
      }),
    });
    if (!response.ok) {
      // Look at the error message
      // It might be a configuration issue
      console.error(`${response.status}: ${(await response.text()) || response.statusText}`);
      process.exit(response.status);
    }

    const {id, url} = await response.json();
  ```

  ```bash cURL
  curl --request POST \
    --url https://api.gladia.io/v2/live \
    --header 'Content-Type: application/json' \
    --header 'x-gladia-key: YOUR_GLADIA_API_KEY' \
    --data '{
      "encoding": "wav/pcm",
      "sample_rate": 16000,
      "bit_depth": 16,
      "channels": 1
      }
    '
  ```
</CodeGroup>

You'll receive a response with a WebSocket URL to connect to. If you loose connection, you can reconnect to that same URL and resume where you left off. Here's an example of a response:

```json
{
  "id": "636c70f6-92c1-4026-a8b6-0dfe3ecf826f",
  "url": "wss://api.gladia.io/v2/live?token=636c70f6-92c1-4026-a8b6-0dfe3ecf826f"
}
```

## Connect to the WebSocket

Now that you've initiated the session and have the URL, you can connect to the WebSocket using your preferred language/framework. Here's an example in JavaScript:

<CodeGroup>
  ```javascript JavaScript
    import WebSocket from "ws";

    const socket = new WebSocket(url);

    socket.addEventListener("open", function() {
      // Connection is opened. You can start sending audio chunks.
    });

    socket.addEventListener("error", function(error) {
      // An error occurred during the connection.
      // Check the error to understand why
    });

    socket.addEventListener("close", function({code, reason}) {
      // The connection has been closed
      // If the "code" is equal to 1000, it means we closed intentionally the connection (after the end of the session for example).
      // Otherwise, you can reconnect to the same url.
    });

    socket.addEventListener("message", function(event) {
      // All the messages we are sending are in JSON format
      const message = JSON.parse(event.data.toString());
      console.log(message);
    });
  ```
</CodeGroup>

## Send audio chunks

You can now start sending us your audio chunks through the WebSocket. You can send them directly as binary, or in JSON by encoding your chunk in base64, like this:

<CodeGroup>
  ```javascript JavaScript
    // as binary
    socket.send(buffer);

    // as json
    socket.send(JSON.stringify({
      type: 'audio_chunk',
      data: {
        chunk: buffer.toString("base64"),
      },
    }));
  ```
</CodeGroup>

## Read messages

During the whole session, we will send various messages through the WebSocket, the callback URL or webhooks. You can specify which kind of messages you want to receive in the initial configuration. See [`messages_config`](/api-reference/v2/live/init) for WebSocket messages and [`callback_config`](/api-reference/v2/live/init) for callback messages.

Here's an example of how to read a [`transcript`](/api-reference/v2/live/message/transcript) message received through a WebSocket:

<CodeGroup>
  ```javascript JavaScript
    socket.addEventListener("message", function(event) {
      // All the messages we are sending are in JSON format
      const message = JSON.parse(event.data.toString());
      if (message.type === 'transcript' && message.data.is_final) {
        console.log(`${message.data.id}: ${message.data.utterance.text}`)
      }
    });
  ```
</CodeGroup>

## Stop the recording

Once you're done, send us the `stop_recording` message. We will process remaining audio chunks and start the post-processing phase, in which we put together the final audio file and results with the add-ons you requested. 

You'll receive a message at every step of the process in the WebSocket, or in the callback if configured. Once the post-processing is done, the WebSocket is closed with a code 1000.

<CodeGroup>
  ```javascript JavaScript
    socket.send(JSON.stringify({
      type: "stop_recording",
    }));
  ```
</CodeGroup>

<Note>
  Instead of sending the `stop_recording` message, you can also close the WebSocket with the code 1000.
  We will still do the post-processing in background and send you the messages through the callback you defined.

  <CodeGroup>
    ```javascript JavaScript
      socket.close(1000);
    ```
  </CodeGroup>
</Note>

## Get the final results

If you want to get the complete result, you can call the [`GET /v2/live/:id` endpoint](/api-reference/v2/live/get) with the `id` you received from the initial request.

<CodeGroup>
  ```javascript JavaScript
    const response = await fetch(`https://api.gladia.io/v2/live/${id}`, {
      method: 'GET',
      headers: {
        'X-Gladia-Key': '<YOUR_GLADIA_API_KEY>',
      },
    });
    if (!response.ok) {
      // Look at the error message
      // It might be a configuration issue
      console.error(`${response.status}: ${(await response.text()) || response.statusText}`)
      return;
    }

    const result = await response.json();
    console.log(result)
  ```

  ```bash cURL
  curl --request GET \
    --url https://api.gladia.io/v2/live/ID_OF_THE_SESSION \
    --header 'x-gladia-key: YOUR_GLADIA_API_KEY'
  ```
</CodeGroup>

<Samples />