---
title: Features
description: "Core features of the Gladia Pre-recorded STT API"
---

The core functionality of the Gladia API is its Speech Recognition model, designed to convert spoken language
 into written text. This serves as the basis for all Gladia API offerings.


<Note>
Do you want to know more about Gladia latest speech-to-text recognition AI model?
Discover our state-of-the-art ASR model [ Whisper Zero now.](https://www.gladia.io/whisper-zero)
</Note>

 Additional capabilities, like Speaker Diarization, Summarization, Translation, Custom Prompts and more can be integrated seamlessly
 into the transcription process by including extra parameters in the transcription request.



## Word-level timestamps

Instead of just getting utterances start and end timestamps, **Gladia** Speech-to-text API provides by **default** the
**Word-level timestamps** feature. It lets you know the exact timestamp for each word and give you a more precise transcription.
 This feature is particularly useful for detailed analysis, as it allows you to pinpoint the exact moment each word is spoken, facilitating
  a more accurate synchronization with audio or video files.

Under each utterance, you'll find a `words` property like this:

```json
// other properties...
"utterances": [
    {
      "words": [
        {
          "word": "Split",
          "start": 0.21001999999999998,
          "end": 0.69015,
          "confidence": 1
        },
        {
          "word": " infinity",
          "start": 0.91021,
          "end": 1.55038,
          "confidence": 0.95
        },
        ...
      ]
    }
  ]
```



## Export SRT or VTT caption files

You can export completed transcripts in both SRT and VTT format, which can be used for subtitles and captions in videos.

<Tip>
You can use the `subtitles` feature alongside the `translation` feature. 
You'll have your subtitles in the original language, and **also** in languages you targeted for the translation!
</Tip>

```json request data
{
  "audio_url": "YOUR_AUDIO_URL",
  "subtitles": true,
  "subtitles_config": {
    "formats": ["srt", "vtt"],
    "minimum_duration": 1,
    "maximum_duration": 5,
    "maximum_characters_per_row": 42,
    "maximum_rows_per_caption": 2,
    "style": "compliance"
  }
}
```

The `subtitles_config` object supports the following options:

- `formats`: Array of subtitle formats to generate (options: "srt", "vtt")
- `minimum_duration`: Minimum duration of a subtitle in seconds (minimum: 0)
- `maximum_duration`: Maximum duration of a subtitle in seconds (minimum: 1, maximum: 30)
- `maximum_characters_per_row`: Maximum number of characters per row in a subtitle (minimum: 1)
- `maximum_rows_per_caption`: Maximum number of rows per caption (minimum: 1, maximum: 5)
- `style`: Style of the subtitles. Options are:
  - "default": Standard subtitle style
  - "compliance": Follows the compliance mode as described in [Library of Congress Recommended Format Statement](https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml)

The `JSON` response will include a new property `subtitles` which is an array of every formats you requested.
With the given example, `subtitles` will contains 2 items of shape:

```json
{
  "format": "srt", //format name
  "subtitles": "1\n00:00:00,210 --> 00:00:04,711....." // subtitles
}
```

## Context prompt

If you know the context of the audio you're sending, you can provide it in the `context_prompt`.

```json request data
{
  "audio_url": "YOUR_AUDIO_URL",
  "context_prompt": "A conversation between Sansa Stark and Peter Baelish from the Game of Thrones series.",
}
```


## Dual-channel or Multiple channels transcription

If you have multiples channels in your audio file with different content each, Gladia API automatically transcribe them.
In the transcription result, you will get for each utterances a `channel` key corresponding to the channels the transcription
 came from.

<Warning>
Sending an audio with 2 different channels (that does not contains the same audio data), will be billed twice as 2 different audios.
If your audio has multiple channels but has the same audio content on each channels, it will only billed once.

**TLDR**: We charge every unique channel in an audio file, we do not charge if channels are duplicates.
</Warning>

## Adding custom metadata

You can add metadata to your transcription using the `custom_metadata` input during your POST request on `/v2/pre-recorded` endpoint.
This will allow you to recognize your transcription when you get its data from the GET `/v2/pre-recorded/:id` endpoint, but more important, it will allow you to use it as a filter in the GET `/v2/pre-recorded` list endpoint.
For example, you can add the following when asking for a transcription:

```json
"custom_metadata": {
    "internalUserId": 2348739875894375,
    "paymentMethod": {
        "last4Digits": 4576
     },
     "internalUserName": "Spencer"
}
```

And then, use the following GET request to filter results like:
```
https://api.gladia.io/v2/pre-recorded?custom_metadata={"internalUserId": "2348739875894375"}
```
or
```
https://api.gladia.io/v2/pre-recorded?custom_metadata={"paymentMethod": {"last4Digits": 4576}, "internalUserName": "Spencer"}
```

<Warning>

`custom_metadata` cannot be longer than 2000 characters when stringified.

</Warning>
