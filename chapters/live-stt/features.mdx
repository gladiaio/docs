---
title: "Features"
description: "Core features of Gladia's real-time speech-to-text (STT) API "
---

import CustomVocabularyInputDescription from '/snippets/custom-vocabulary-input-description.mdx'
import CustomSpellingStartDescription from '/snippets/custom-spelling-start-description.mdx'
import CustomSpellingEndDescription from '/snippets/custom-spelling-end-description.mdx'
import Languages from '/snippets/languages.mdx'

<Note>All the configuration properties described below are defined in the [POST /v2/live endpoint](/api-reference/v2/live/init).</Note>

<Languages />

## Word-level timestamps

Instead of just getting timestamps for when utterances begin and end, Gladia's real-time API provides **word-level timestamps**. This lets you know the exact timestamp for each word,  giving you a more precise transcription, facilitating detailed analysis and more accurate synchronization with audio and video files.

To enable it, pass the following configuration:

```json
{
  "realtime_processing": {
    "words_accurate_timestamps": true
  }
}
```

Under each utterance, you'll find a `words` property, like this:

```json
{
  // ... other utterance properties
  "words": [
    {
      "word": "Split",
      "start": 0.21001999999999998,
      "end": 0.69015,
      "confidence": 1
    },
    {
      "word": " infinity",
      "start": 0.91021,
      "end": 1.55038,
      "confidence": 0.95
    },
  ]
}
```

## Partial transcripts

Partial transcripts provide a low-latency streaming transcription as words are spoken, offering immediate insights before the final, high-accuracy transcript is ready.

To enable the partial transcripts, you must add the `receive_partial_transcripts` property to the `messages_config` object in your request.

```json
{
    "encoding": "wav/pcm",
    "sample_rate": 16000,
    "bit_depth": 16,
    "channels": 1,
    "language_config": {
        "languages": ["en"],
        "code_switching": false
    },
    "messages_config": {
        "receive_partial_transcripts": true,
        "receive_final_transcripts": true
    }
}
```
  
With this configuration, you will receive both the partial transcripts as they are generated and the final, most accurate version of each utterance.

To reduce the total response time and create a more fluid user experience, partial transcripts use a faster, smaller model than the one used for final transcripts, trading a small amount of accuracy for a large gain in latency (< 100ms).

<Note>Partial transcripts accuracy deteriorates when multiple languages and/or code switching are enabled. For best results, we recommend to limit the number of languages.</Note>

When you set `receive_partial_transcripts` to `true`, the real-time API will send transcript messages for both intermediate and final results. 
To distinguish between them, the message payload includes the [`is_final`](https://docs.gladia.io/api-reference/v2/live/message/transcript#schema-data-is-final) boolean field.

- `"is_final": false`: The message contains a partial transcript, which is subject to change.

- `"is_final": true`: The message contains the final, most accurate transcript for an utterance. This transcript will not change.

In a same utterance, the partial and final transcripts share the same `data.id`.



## Custom vocabulary

To enhance the precision of words you know will recur often in your transcription, use the `custom_vocabulary` feature.<br />

```json
{
  "realtime_processing": {
    "custom_vocabulary": true,
    "custom_vocabulary_config": {
      "vocabulary": [
        "Westeros", 
        {"value": "Stark"}, 
        { 
          "value": "Night's Watch",
          "pronunciations": ["Nightz Watch"],
          "intensity": 0.4,
          "language": "en"
        }
      ],
      "default_intensity": 0.6
    }
  }
}
```
<CustomVocabularyInputDescription />

## Custom spelling
<CustomSpellingStartDescription />

```json request data
{
  "realtime_processing": {
    "custom_spelling": true,
    "custom_spelling_config": {
      "spelling_dictionary": {
          "Gorish": ["ghorish", "gaurish", "gaureish"],
          "Data Science": ["data-science", "data science"],
          ".": ["period", "full stop"],
          "SQL": ["sequel"]
      }
    }
  }
}
```
<CustomSpellingEndDescription />

## Translation

This feature allows you to get both the original transcription and its translation in your specified target language(s) in real-time.

```json
{
  "realtime_processing": {
    "translation": true,
    "translation_config": {
      "target_languages": ["fr", "es"],  // Translate to French and Spanish
      "model": "base",                    // "base" or "enhanced"
      "context_adaptation": true,         // Enable context-aware translation
      "context": "Technical support call about software issues",
      "informal": false                   // Use formal language
    }
  }
}
```

### Translation Configuration Options:

- **`target_languages`**: Array of language codes for translation outputs (e.g., `["fr", "es"]`)
- **`model`**: Translation model - `"base"` (fast) or `"enhanced"` (higher quality, context-aware)
- **`context_adaptation`**: Boolean to enable/disable context-aware translation features (default: `true`)
- **`context`**: String providing context to improve translation accuracy (default: `""`)
- **`informal`**: Boolean to force informal language forms when available (default: `false`)

With this feature enabled, you'll receive a [`translation` message](/api-reference/v2/live/message/translation) for each [`transcript` message](/api-reference/v2/live/message/transcript) and target language.

## Multiple channels

If you have multiple channels in your audio stream, specify the count in the configuration:

```json
{
  "channels": 2
}
```

Gladia's real-time API will automatically split the channels and transcribe them separately.
For each utterance, you'll get a `channel` key corresponding to the channel the utterance came from.

<Warning>
  Transcribing an audio stream with multiple channels is billed per channel. For example, an audio stream with 2 channels will be billed as double the audio duration, even if the channels are identical.
</Warning>

<Note>
  For a detailed guide on how to merge multiple audio tracks into a single multi-channel stream and send it over a WebSocket, see the [Sending multiple audio tracks over a single WebSocket](/api-reference/live-flow#sending-multiple-audio-tracks-over-a-single-websocket) section.
</Note>

## Attaching custom metadata

You can attach metadata to your real-time transcription session using the `custom_metadata` property. This'll make it easy to recognize your transcription when you receive data from the [GET `/v2/live/:id` endpoint](/api-reference/v2/live/get). And more importantly, you'll be able to use it as a filter in the [GET `/v2/live` list endpoint](/api-reference/v2/live/list).
For example, you can add the following to your configuration:

```json
"custom_metadata": {
    "internalUserId": 2348739875894375,
    "paymentMethod": {
        "last4Digits": 4576
     },
     "internalUserName": "Spencer"
}
```

And use a GET request to filter results, like this:

```
https://api.gladia.io/v2/live?custom_metadata={"internalUserId": "2348739875894375"}
```

or like this:

```
https://api.gladia.io/v2/live?custom_metadata={"paymentMethod": {"last4Digits": 4576}, "internalUserName": "Spencer"}
```

<Warning>
  `custom_metadata` cannot be longer than 2000 characters when stringified.
</Warning>