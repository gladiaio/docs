---
title: "Features"
description: "Features overview of Gladia's Real-Time speech-to-text (STT) API."
---


| **Feature**                                                                       | **Description**                                                                                            |
|-----------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|
| [Sentiment and Emotion Analysis](/chapters/audio-intelligence/pages/sentiment-analysis) | Extract sentiments and emotions from the audio, like confusion or interest.                                |
| [Name Entity Recognition](/chapters/audio-intelligence/pages/named-entity-recognition)  | Automatically identifies and categorizes key information in the audio, like phone number or email address. |
| [Summarization](/chapters/audio-intelligence/pages/summarization)  | Get important information from your conversation. This analysis is performed after the real-time transcription is stopped. |



## IN PROGRESS bellow this part


<Note>All the configuration properties described below are defined in the [POST /v2/live endpoint](/api-reference/v2/live/init).</Note>

## Language configuration

### Single language

If you know the language of the conversation in advance, specify it in the `language_config.languages` parameter to ensure the best transcription results.

```json
{
  "language_config": {
    "languages": ["en"]
  }
}
```

If the spoken language is unknown, you can:
- Omit the `language_config.languages` parameter; the model will automatically detect the language from the first few seconds of audio **across all supported languages**.
- Specify multiple languages in the `language_config.languages` parameter; the model will detect the language from the first few seconds of audio **within the provided options**.

<CodeGroup>

```json Limited options
{
  // Will limit to detect from English, French or Spanish
  "language_config": {
    "languages": ["en", "fr", "es"]
  }
}
```

```json All languages
{
  // You can omit the parameter
  "language_config": {
    "languages": []
  }
}
```

</CodeGroup>

### Multiple languages <br/>(Code-switching)

If you expect multiple languages to be spoken during the conversation, enable the `language_config.code_switching` parameter. This will allow the model to switch languages dynamically and reflect it in the transcription results.

As with single-language configuration, you can either let the model detect the language from **all supported languages** or specify a **set of options** to narrow down the selection.

<CodeGroup>

```json Limited options
{
  "language_config": {
    // Will limit to detect from English, French or Spanish
    "languages": ["en", "fr", "es"],
    "code_switching": true
  }
}
```

```json All languages
{
  "language_config": {
    // You can omit the languages parameter
    "languages": [],
    "code_switching": true
  }
}
```

</CodeGroup>

<br/>

<Tip>
It is recommended to limit the number of languages to avoid incorrect detection, either in single or multiple languages configuration. Some languages, such as those from Eastern European countries, have similar sounds, which may cause the model to confuse them and produce a transcription in the wrong language.
</Tip>

## Word-level timestamps

Instead of just getting timestamps for when utterances begin and end, Gladia's real-time API provides **word-level timestamps**. This lets you know the exact timestamp for each word,  giving you a more precise transcription, facilitating detailed analysis and more accurate synchronization with audio and video files.

To enable it, pass the following configuration:

```json
{
  "realtime_processing": {
    "words_accurate_timestamps": true
  }
}
```

Under each utterance, you'll find a `words` property, like this:

```json
{
  // ... other utterance properties
  "words": [
    {
      "word": "Split",
      "start": 0.21001999999999998,
      "end": 0.69015,
      "confidence": 1
    },
    {
      "word": " infinity",
      "start": 0.91021,
      "end": 1.55038,
      "confidence": 0.95
    },
  ]
}
```

## Custom vocabulary

To enhance the precision of words you know will recur often in your transcription, use the `custom_vocabulary` feature.<br />
Custom vocabulary has the following limitations:

* Global limit of **10k characters**
* No more than **100 entries**
* Each element can't contain more than **5 words**

```json
{
  "realtime_processing": {
    "custom_vocabulary": true,
    "custom_vocabulary_config": {
      "vocabulary": ["Westeros", "Stark", "Night's Watch"]
    }
  }
}
```

## Multiple channels

If you have multiple channels in your audio stream, specify the count in the configuration:

```json
{
  "channels": 2
}
```

Gladia's real-time API will automatically split the channels and transcribe them separately.
For each utterance, you'll get a `channel` key corresponding to the channel the utterance came from.

<Warning>
  Transcribing an audio stream with multiple channels will be billed exponentially. For example, an audio stream with 2 channels will be billed as double the audio duration, even if the channels are identical.
</Warning>

## Attaching custom metadata

You can attach metadata to your real-time transcription session using the `custom_metadata` property. This'll make it easy to recognize your transcription when you receive data from the [GET `/v2/live/:id` endpoint](/api-reference/v2/live/get). And more importantly, you'll be able to use it as a filter in the [GET `/v2/live` list endpoint](/api-reference/v2/live/list).
For example, you can add the following to your configuration:

```json
"custom_metadata": {
    "internalUserId": 2348739875894375,
    "paymentMethod": {
        "last4Digits": 4576
     },
     "internalUserName": "Spencer"
}
```

And use a GET request to filter results, like this:

```
https://api.gladia.io/v2/live?custom_metadata={"internalUserId": "2348739875894375"}
```

or like this:

```
https://api.gladia.io/v2/live?custom_metadata={"paymentMethod": {"last4Digits": 4576}, "internalUserName": "Spencer"}
```

<Warning>
  `custom_metadata` cannot be longer than 2000 characters when stringified.
</Warning>